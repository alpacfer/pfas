{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo Block Matching Overview\n",
    "Stereo block matching is a method used in computer vision to estimate depth by comparing two images (usually a left and right image from a stereo camera setup). The goal is to find corresponding pixels between the two images to compute disparities, which can then be used to infer depth information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Step 1: Sum of Absolute Differences (SAD)\n",
    "### Objective:\n",
    "Implement a function that calculates the **Sum of Absolute Differences (SAD)** between two equal-sized images (or image patches).\n",
    "\n",
    "### Concept Explanation:\n",
    "- **Sum of Absolute Differences (SAD)** is a simple and commonly used metric for block matching. It computes the absolute difference between corresponding pixel values of two images or image patches and sums them up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "1. **Read the Images**:\n",
    "    - Use a library like `OpenCV` (cv2) or `PIL` (Image) to read `nose_left.png` and `nose_right.png`.\n",
    "    - Ensure the images are converted to grayscale if they are not already, as color can complicate the SAD calculation.\n",
    "2. **Calculate SAD**:\n",
    "    - Subtract one image from the other.\n",
    "    - Take the absolute value of the result.\n",
    "    - Sum all the values to get the SAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the image\n",
    "left_image = cv2.imread('nose_left.png')\n",
    "right_image = cv2.imread('nose_right.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "left_image_gray = cv2.cvtColor(left_image, cv2.COLOR_BGR2GRAY)\n",
    "right_image_gray = cv2.cvtColor(right_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(left_image_gray, cmap='gray')\n",
    "plt.title('Left Image')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(right_image_gray, cmap='gray')\n",
    "plt.title('Right Image')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SAD(image1, image2):\n",
    "    if left_image_gray.shape != right_image_gray.shape:\n",
    "        raise ValueError(\"The two images must have the same dimensions for SAD calculation.\")\n",
    "    \n",
    "    image1 = np.asarray(image1)\n",
    "    image2 = np.asarray(image2)\n",
    "    difference = np.abs(image1 - image2)\n",
    "    sad = np.sum(difference)\n",
    "    return sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SAD between the two images is: 7657\n"
     ]
    }
   ],
   "source": [
    "# Calculate the SAD\n",
    "sad = calculate_SAD(left_image_gray, right_image_gray)\n",
    "print('The SAD between the two images is:', sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Step 2: Matching with Multiple Templates\n",
    "### Objective:\n",
    "Find which of the three images (`nose1.png`, `nose2.png`, `nose3.png`) best matches `nose_left.png` using the SAD function.\n",
    "\n",
    "### Concept Explanation:\n",
    "- **Template Matching**: This involves sliding the template over an image to find the region that best matches the template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "1. **Read the Template and Candidate Images**:\n",
    "    - Load `nose_left.png` as the template.\n",
    "    - Load `nose1.png`, `nose2.png`, and `nose3.png` as candidate images.\n",
    "2. **Compute SAD for Each Candidate**:\n",
    "    - Use the `calculate_sad` function from Step 1 to compute the SAD between the template and each candidate image.\n",
    "3. **Determine the Best Match**:\n",
    "    - The candidate with the lowest SAD value is the best match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAD for nose1.png: 4551\n",
      "SAD for nose2.png: 5613\n",
      "SAD for nose3.png: 1490\n",
      "The best match is nose3.png with a SAD value of 1490.\n"
     ]
    }
   ],
   "source": [
    "# List of candidate image filenames\n",
    "candidate_images_filenames = ['nose1.png', 'nose2.png', 'nose3.png']\n",
    "\n",
    "# Read the template image\n",
    "left_image_gray = cv2.imread('nose_left.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize variables to store the best match information\n",
    "best_sad = float('inf')  # Initialize with a very large value\n",
    "best_match = None\n",
    "\n",
    "# Iterate through the candidate images\n",
    "for candidate_filename in candidate_images_filenames:\n",
    "    # Read the candidate image\n",
    "    candidate_image_gray = cv2.imread(candidate_filename, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Ensure the candidate image has the same size as the template image\n",
    "    if candidate_image_gray.shape != left_image_gray.shape:\n",
    "        raise ValueError(f\"The candidate image {candidate_filename} has a different size than the template image.\")\n",
    "    \n",
    "    # Calculate the SAD between the template and the candidate image\n",
    "    sad_value = calculate_SAD(left_image_gray, candidate_image_gray)\n",
    "    print(f\"SAD for {candidate_filename}: {sad_value}\")\n",
    "    \n",
    "    # Update the best match if the current SAD is smaller\n",
    "    if sad_value < best_sad:\n",
    "        best_sad = sad_value\n",
    "        best_match = candidate_filename\n",
    "\n",
    "# Output the best match result\n",
    "print(f'The best match is {best_match} with a SAD value of {best_sad}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Step 3: Locating the Nose in a Span\n",
    "### Objective:\n",
    "Use the SAD function to find where the nose is located in `nose_span.png`.\n",
    "\n",
    "### Concept Explanation:\n",
    "- **1D Search Along a Row**: Since the images are rectified, corresponding features lie along the same row. You can slide the template horizontally across the span to find the best match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Approach:\n",
    "1. **Read the Template and Span Image**:\n",
    "    - Load `nose_left.png` as the template.\n",
    "    - Load `nose_span.png` as the image where you need to find the nose.\n",
    "2. **Sliding Window**:\n",
    "    - Loop over the possible horizontal positions in `nose_span.png` where the template can fit.\n",
    "    - At each position, extract a patch the same size as the template.\n",
    "    - Compute the SAD between the template and the patch.\n",
    "3. **Record the Position with the Lowest SAD**:\n",
    "    - Keep track of the position (horizontal index) where the SAD is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Read the template (nose_left.png) and the larger span image (nose_span.png)\n",
    "template_image = cv2.imread('nose_left.png', cv2.IMREAD_GRAYSCALE)\n",
    "span_image = cv2.imread('nose_span.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if both images were loaded successfully\n",
    "if template_image is None or span_image is None:\n",
    "    raise ValueError(\"One or both images could not be loaded. Check file paths.\")\n",
    "\n",
    "# Get the dimensions of the template\n",
    "template_height, template_width = template_image.shape\n",
    "\n",
    "# Ensure the span image is wide enough for the template\n",
    "if span_image.shape[1] < template_width:\n",
    "    raise ValueError(\"The span image is not wide enough to fit the template.\")\n",
    "\n",
    "# Convert span image to RGB so colors can be drawn on top\n",
    "span_image_rgb = cv2.cvtColor(span_image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Initialize variables to track the best match\n",
    "best_sad = float('inf')  # Large initial value\n",
    "best_x = -1  # Initial position for the best match\n",
    "\n",
    "# Prepare the plot for visualization\n",
    "plt.ion()  # Turn on interactive mode to update the plot in real time\n",
    "fig, ax = plt.subplots()  # Create a new figure for the external window\n",
    "\n",
    "# Perform sliding window search along the row of the span image\n",
    "for x in range(span_image_rgb.shape[1] - template_width + 1):\n",
    "    # Extract a patch from the span image that matches the template size\n",
    "    patch = span_image[0:template_height, x:x+template_width]\n",
    "    \n",
    "    # Calculate the SAD between the template and the current patch\n",
    "    sad_value = calculate_SAD(template_image, patch)\n",
    "    \n",
    "    # Update the best match if a lower SAD is found\n",
    "    if sad_value < best_sad:\n",
    "        best_sad = sad_value\n",
    "        best_x = x\n",
    "    \n",
    "    # Visualization: Plot the span image and highlight the current window\n",
    "    span_image_copy = span_image_rgb.copy()  # Make a copy of the RGB image\n",
    "    \n",
    "    # Draw a red rectangle around the current patch\n",
    "    cv2.rectangle(span_image_copy, (x, 0), (x+template_width, template_height), (255, 0, 0), 2)  # Red color in RGB\n",
    "    \n",
    "    # Clear the previous plot and show the current one\n",
    "    ax.clear()\n",
    "    ax.imshow(span_image_copy)  # Remove 'cmap' to show the image in RGB\n",
    "    ax.set_title(f'Current position: {x}, SAD: {sad_value}')\n",
    "    plt.draw()\n",
    "    plt.pause(0.05)  # Pause to create an animation effect\n",
    "\n",
    "# Once the process is done, highlight the best match with a green rectangle\n",
    "span_image_copy = span_image_rgb.copy()\n",
    "cv2.rectangle(span_image_copy, (best_x, 0), (best_x+template_width, template_height), (0, 255, 0), 2)  # Green color in BGR\n",
    "\n",
    "# Show the final result\n",
    "ax.clear()\n",
    "ax.imshow(span_image_copy)\n",
    "ax.set_title(f'Best match at x={best_x} with SAD={best_sad}')\n",
    "plt.draw()\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Template Matching Implementation (Challenge)\n",
    "### Objective:\n",
    "Implement a full template matching function that computes the **disparity map** for `tsukuba_left.png` and `tsukuba_right.png`.\n",
    "\n",
    "### Concept Explanation:\n",
    "- **Disparity Map**: A map that represents the displacement (disparity) of pixels between the left and right images.\n",
    "- **Block Matching Algorithm**: For each block (sub-image) in the left image, find the best matching block in the right image within a certain search range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "1. **Read the Stereo Images**:\n",
    "    - Load `tsukuba_left.png` and `tsukuba_right.png`.\n",
    "    - Convert them to grayscale if necessary.\n",
    "2. **Set Parameters**:\n",
    "    - Define the block (template) size, e.g., 7x7.\n",
    "    - Define the maximum disparity (search range).\n",
    "3. **Initialize the Disparity Map**:\n",
    "    - Create an empty array to store disparity values, the same size as the input images.\n",
    "4. **Iterate Over Each Pixel (excluding borders)**:\n",
    "    - For each pixel position `(y, x)` in the left image:\n",
    "        - Extract the template/block centered at `(y, x)`.\n",
    "        - Define the corresponding row in the right image.\n",
    "        - Search within the defined disparity range along the row in the right image.\n",
    "        - For each candidate position in the right image:\n",
    "            - Extract the matching block.\n",
    "            - Compute the SAD between the template and the candidate block.\n",
    "            - Record the disparity (difference in x-coordinate) that gives the minimum SAD.\n",
    "5. **Store the Disparity Values**:\n",
    "    - Update the disparity map with the found disparity for each pixel.\n",
    "6. **Post-Processing (Optional)**:\n",
    "    - Apply filtering to the disparity map to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the stereo images (assuming they are grayscale)\n",
    "left_image = cv2.imread('tsukuba_left.png', cv2.IMREAD_GRAYSCALE)\n",
    "right_image = cv2.imread('tsukuba_right.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images were loaded correctly\n",
    "if left_image is None or right_image is None:\n",
    "    raise ValueError(\"One or both stereo images could not be loaded.\")\n",
    "\n",
    "# Set block size and maximum disparity\n",
    "block_size = 7  # Template size\n",
    "max_disparity = 16  # Maximum number of pixels to search in the right image\n",
    "\n",
    "# Initialize the disparity map (same size as the input images)\n",
    "disparity_map = np.zeros(left_image.shape, dtype=np.float32)\n",
    "\n",
    "# Compute the padding size based on block size\n",
    "pad_size = block_size // 2\n",
    "\n",
    "# Pad both images to handle edge pixels\n",
    "left_image_padded = cv2.copyMakeBorder(left_image, pad_size, pad_size, pad_size, pad_size, cv2.BORDER_CONSTANT, 0)\n",
    "right_image_padded = cv2.copyMakeBorder(right_image, pad_size, pad_size, pad_size, pad_size, cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "# Iterate over each pixel in the left image (excluding the borders)\n",
    "for y in range(pad_size, left_image.shape[0] - pad_size):\n",
    "    for x in range(pad_size, left_image.shape[1] - pad_size):\n",
    "        # Extract the block from the left image\n",
    "        left_block = left_image_padded[y-pad_size:y+pad_size+1, x-pad_size:x+pad_size+1]\n",
    "\n",
    "        # Initialize variables to store the best match\n",
    "        best_sad = float('inf')  # Large initial SAD value\n",
    "        best_disparity = 0  # Best disparity\n",
    "\n",
    "        # Search for the best match within the disparity range in the right image\n",
    "        for d in range(max_disparity):\n",
    "            # Ensure the candidate block is within image bounds\n",
    "            if x - d < pad_size:\n",
    "                break\n",
    "\n",
    "            # Extract the block from the right image at disparity d\n",
    "            right_block = right_image_padded[y-pad_size:y+pad_size+1, (x-d)-pad_size:(x-d)+pad_size+1]\n",
    "\n",
    "            # Compute the SAD (Sum of Absolute Differences) between the blocks\n",
    "            sad = np.sum(np.abs(left_block - right_block))\n",
    "\n",
    "            # Update the best match if the SAD is smaller\n",
    "            if sad < best_sad:\n",
    "                best_sad = sad\n",
    "                best_disparity = d\n",
    "\n",
    "        # Store the best disparity in the disparity map\n",
    "        disparity_map[y, x] = best_disparity\n",
    "\n",
    "# Normalize the disparity map to 0-255 for visualization\n",
    "disparity_map_normalized = cv2.normalize(disparity_map, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Display the disparity map\n",
    "plt.imshow(disparity_map_normalized, cmap='gray')\n",
    "plt.title('Disparity Map')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the stereo images (assuming they are grayscale)\n",
    "left_image = cv2.imread('tsukuba_left.png', cv2.IMREAD_GRAYSCALE)\n",
    "right_image = cv2.imread('tsukuba_right.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images were loaded correctly\n",
    "if left_image is None or right_image is None:\n",
    "    raise ValueError(\"One or both stereo images could not be loaded.\")\n",
    "\n",
    "# Set block size and maximum disparity\n",
    "block_size = 7  # Template size\n",
    "max_disparity = 16  # Maximum number of pixels to search in the right image\n",
    "\n",
    "# Initialize the disparity map (same size as the input images)\n",
    "disparity_map = np.zeros(left_image.shape, dtype=np.float32)\n",
    "\n",
    "# Compute the padding size based on block size\n",
    "pad_size = block_size // 2\n",
    "\n",
    "# Pad both images to handle edge pixels\n",
    "left_image_padded = cv2.copyMakeBorder(left_image, pad_size, pad_size, pad_size, pad_size, cv2.BORDER_CONSTANT, 0)\n",
    "right_image_padded = cv2.copyMakeBorder(right_image, pad_size, pad_size, pad_size, pad_size, cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "# Initialize a figure for visualization\n",
    "plt.ion()  # Interactive mode\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))  # Create 3 subplots for visualization\n",
    "\n",
    "# Define the zoom window size\n",
    "zoom_size = 50  # Adjust this value as needed\n",
    "\n",
    "# Main loop to compute disparity map\n",
    "for y in range(pad_size, left_image.shape[0] - pad_size):\n",
    "    for x in range(pad_size, left_image.shape[1] - pad_size):\n",
    "        # Extract the block from the left image\n",
    "        left_block = left_image_padded[y-pad_size:y+pad_size+1, x-pad_size:x+pad_size+1]\n",
    "\n",
    "        # Initialize variables to store the best match\n",
    "        best_sad = float('inf')  # Large initial SAD value\n",
    "        best_disparity = 0  # Best disparity\n",
    "\n",
    "        # Search for the best match within the disparity range in the right image\n",
    "        for d in range(max_disparity):\n",
    "            # Ensure the candidate block is within image bounds\n",
    "            if x - d < pad_size:\n",
    "                break\n",
    "\n",
    "            # Extract the block from the right image at disparity d\n",
    "            right_block = right_image_padded[y-pad_size:y+pad_size+1, (x-d)-pad_size:(x-d)+pad_size+1]\n",
    "\n",
    "            # Compute the SAD (Sum of Absolute Differences) between the blocks\n",
    "            sad = np.sum(np.abs(left_block - right_block))\n",
    "\n",
    "            # Update the best match if the qSAD is smaller\n",
    "            if sad < best_sad:\n",
    "                best_sad = sad\n",
    "                best_disparity = d\n",
    "\n",
    "            # Visualization: Update every time a block is compared\n",
    "            # Determine the coordinates for the zoomed-in region\n",
    "            y_min = max(y - zoom_size // 2, 0)\n",
    "            y_max = min(y + zoom_size // 2, left_image.shape[0])\n",
    "            x_min = max(x - zoom_size // 2, 0)\n",
    "            x_max = min(x + zoom_size // 2, left_image.shape[1])\n",
    "\n",
    "            # Crop the images to the zoomed-in region\n",
    "            left_zoom = left_image[y_min:y_max, x_min:x_max]\n",
    "            right_x_min = x_min - best_disparity\n",
    "            right_x_max = x_max - best_disparity\n",
    "\n",
    "            # Ensure indices are within bounds for the right image\n",
    "            if right_x_min < 0:\n",
    "                right_x_min = 0\n",
    "            if right_x_max > right_image.shape[1]:\n",
    "                right_x_max = right_image.shape[1]\n",
    "\n",
    "            right_zoom = right_image[y_min:y_max, right_x_min:right_x_max]\n",
    "\n",
    "            # Clear previous plots\n",
    "            ax[0].clear()\n",
    "            ax[1].clear()\n",
    "\n",
    "            # Show the zoomed-in left and right images\n",
    "            ax[0].imshow(left_zoom, cmap='gray')\n",
    "            ax[0].set_title(f\"Left Image Zoomed Window: (y={y}, x={x})\")\n",
    "\n",
    "            ax[1].imshow(right_zoom, cmap='gray')\n",
    "            ax[1].set_title(f\"Right Image Zoomed Window (Disparity={d})\")\n",
    "\n",
    "            # Compute rectangle positions in the cropped images\n",
    "            left_rect_x = (x - pad_size) - x_min\n",
    "            left_rect_y = (y - pad_size) - y_min\n",
    "\n",
    "            right_rect_x = (x - best_disparity - pad_size) - right_x_min\n",
    "            right_rect_y = (y - pad_size) - y_min\n",
    "\n",
    "            # Draw rectangles on the images to represent the blocks\n",
    "            left_rect = plt.Rectangle((left_rect_x, left_rect_y), block_size, block_size,\n",
    "                                      edgecolor='red', facecolor='none')\n",
    "            ax[0].add_patch(left_rect)\n",
    "\n",
    "            right_rect = plt.Rectangle((right_rect_x, right_rect_y), block_size, block_size,\n",
    "                                       edgecolor='red', facecolor='none')\n",
    "            ax[1].add_patch(right_rect)\n",
    "\n",
    "            # Show the updated disparity map\n",
    "            disparity_map[y, x] = best_disparity\n",
    "\n",
    "            ax[2].clear()\n",
    "            ax[2].imshow(disparity_map, cmap='gray')\n",
    "            ax[2].set_title(f\"Disparity Map (y={y}, x={x})\")\n",
    "\n",
    "            # Display the disparity value\n",
    "            plt.suptitle(f\"Current Disparity: {best_disparity}\")\n",
    "            plt.draw()\n",
    "            plt.pause(0.05)  # Small pause to visualize updates\n",
    "\n",
    "# Final disparity map visualization\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "# Normalize the disparity map to 0-255 for visualization\n",
    "disparity_map_normalized = cv2.normalize(disparity_map, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Display the final disparity map\n",
    "plt.imshow(disparity_map_normalized, cmap='gray')\n",
    "plt.title('Final Disparity Map')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
