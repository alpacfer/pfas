{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Support Vector Machines\n",
    "Perception is an important step for autonomous systems. We will look into one method of classifying data given a dataset containing inputs and corresponding targets. In this case we will look at the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), but it could be any arbitrary dataset.\n",
    "\n",
    "Today we will work with classification using [Support Vector Machines (SVM)](https://en.wikipedia.org/wiki/Support-vector_machine).\n",
    "We will use the implementation from the `sklearn` library. \n",
    "\n",
    "**Note**: If the import of the `pandas` library fails because the module isn't installed, install the `pandas` library with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for plotting the fit of your SVM.\n",
    "def plot_fit(X, y, clf):\n",
    "    \"\"\"\n",
    "    X = samples\n",
    "    y = Ground truth\n",
    "    clf = trained model\n",
    "    \"\"\"\n",
    "    h = .02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(1, figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors= \"black\")\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, we're using the Iris dataset. It consists of 150 samples with 4 featuers each.\n",
    "We're using the sepal length and the sepal width as features to predict which species of the Iris flower one sample is.\n",
    "The target classes are integer-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some data to play with\n",
    "iris = sk.datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "display(iris_df)\n",
    "X = iris_df.iloc[:,:2]\n",
    "display(X)\n",
    "y = iris.target\n",
    "print(\"Number of samples ::\", X.shape[0])\n",
    "print(\"Number of features ::\", X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "We will use pandas to manage our data.\n",
    "Initially we will only use the two first data points, i.e. the sepal length and sepal width.\n",
    "\n",
    "We plot the data and we can see all our samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1, figsize=(8, 6))\n",
    "ax = plt.scatter(X['sepal length (cm)'], X[\"sepal width (cm)\"], c=y)\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel(\"sepal width (cm)\")\n",
    "plt.legend(*ax.legend_elements(), title='Target label')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization.\n",
    "Using `sklearn.preprocessing` we can normalize the data to have zero mean and unitary variance.\n",
    "Why could that be important?\n",
    "```{Python}\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "```\n",
    "Plot the data, did you succed with normalizing the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# code here\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / testing split.\n",
    "We now create a training and testing set.\n",
    "The training set is to train our model and the testing set is to make sure we don't overfit to the data. We can use the test set to analyze this.\n",
    "\n",
    "You can use the following function to create your training and testing split:\n",
    "```{Python}\n",
    "train_test_split(data, target, test_size=n)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# code here\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the accuracy of your model\n",
    "Using `LinearSVC` from `sklearn`:\n",
    "```{Python}\n",
    "sk.svm.LinearSVC(penalty='l2', loss='squared_hinge', random_state=0, max_iter=10e4)\n",
    "```\n",
    "[Documentation for LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html?highlight=linearsvc#sklearn.svm.LinearSVC)\n",
    "\n",
    "You can test the accuracy of your trained model with:\n",
    "```{}\n",
    "clf.score(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "And finally, plot your fit with the provided plot function `plot_fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Code goes here\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### 1) Kernel\n",
    "First exersice is to try other kernels than the linear:\n",
    "```{python}\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C))\n",
    "poly_svc = svm.SVC(kernel='poly', degree=degree, C=C))\n",
    "```\n",
    "[SVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "Do you get better results?\n",
    "### 2 ) More dimensions\n",
    "Now use 3 features for each sample. So either you add the petal length or petal width as an additional feature.\n",
    "\n",
    "Can you get a better fit?\n",
    "\n",
    "Can you visualize your predictions? \n",
    "Make a 3D scatterplot with colors for each predicted class.\n",
    "```{Python}\n",
    "fig = plt.figure(1, figsize=(10, 8))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "ax.scatter(x, y, z, c=class_vector)\n",
    "```\n",
    "\n",
    "### 3) Even more dimensions\n",
    "Finally try fitting the classifier with all features, i.e. 4 features per sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
