{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis \n",
    "PCA (Principal component analysis) is a powerful tool often used in dimensionality reduction.\n",
    "\n",
    "We will today use PCA to reduce the dimensionality of the Iris dataset from $X \\in \\mathbb{R}^4$ to $X' \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "# plot data and fit (2d only)\n",
    "def plot_fit(X, y, clf):\n",
    "    \"\"\"\n",
    "    X = samples\n",
    "    y = Ground truth\n",
    "    clf = trained model\n",
    "    \"\"\"\n",
    "    h = .02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(1, figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors= \"black\")\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = sk.datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "display(iris_df)\n",
    "X = StandardScaler().fit_transform(iris_df)\n",
    "target = iris.target\n",
    "print (\"Number of samples ::\", X.shape[0])\n",
    "print(\"Number of features ::\", X.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction.\n",
    "To use PCA in practice, simply use the following function:\n",
    "\n",
    "```{Python}\n",
    "pca = PCA(n_components = n )\n",
    "principalComponents = pca.fit_transform(data_to_transform)\n",
    "\n",
    "```\n",
    "Find the documentation here: [sklearn PCA documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Code here\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the principal components and compare them to X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# code here\n",
    "# replace x, y and x1, y1 with the values from your computed pca and your X\n",
    "###\n",
    "fig = plt.figure(1, figsize=(10, 8))\n",
    "ax = plt.subplot(211)\n",
    "\n",
    "#Plot scaled version\n",
    "x, y = np.random.rand(2, 150)\n",
    "g = plt.scatter(x, y, c = target, cmap = plt.cm.Set1, edgecolor = 'black', s = 20)\n",
    "plt.grid()\n",
    "plt.subplot(212)\n",
    "\n",
    "# Plot principal components\n",
    "x1, y1 = np.random.rand(2, 150)\n",
    "plt.scatter(x1, y1, c = target,cmap = plt.cm.Set1, edgecolor = 'black', s = 20)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance\n",
    "The explained variance tells you how much information (variance) can be attributed to each of the principal components. \n",
    "\n",
    "By using the attribute `explained_variance_ratio_`, you can see that the first principal component explains 72.77% of the variance and the second principal component explains 23.03% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in total our PCA has now expressed 96% of the variance of the dataset.\n",
    "We can use these new components to attempt to fit an SVM like we did in the previous exercise. The lower dimensional data should retain most of the information in the original data and therefore should compete close to on par with a classifier trained on all features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### 1) SVM\n",
    "Apply an SVM to the principal components. How does it perform compared to using only two features per sample?\n",
    "\n",
    "## 2) Three principal components\n",
    "Attempt with three principal components. \n",
    "How much of the variance of the data do these express? \n",
    "\n",
    "Again, make a 3D plot where each point is colored respective to the predicted class from your SVM.\n",
    "\n",
    "## 3) Best accuracy\n",
    "Compare all the different SVM's we have trained. What is the best accuracy you can acheive?. You are also allowed to use different kernels!\n",
    "\n",
    "## 4) Grid search\n",
    "Attempt to perform a grid search with the function provided by `sklearn`.\n",
    "The `gridsearch` function will try a lot of different combinations of parameters for your SVM so you don't have to.\n",
    "```{Python}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "    \n",
    "c = np.logspace(start = -15, stop = 1000, base = 1.02)\n",
    "param_grid = {'C': c}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid = param_grid, cv = 3, n_jobs = -1, scoring = 'accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "```\n",
    "[GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "\n",
    "Are you able to get a better fit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "516.85px",
    "left": "1965px",
    "right": "20px",
    "top": "120px",
    "width": "359px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
