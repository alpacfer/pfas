{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local registration with ICP\n",
    "\n",
    "In the RGBD folder we have the first 400 images from one of the datasets from: [http://redwood-data.org/indoor_lidar_rgbd/download.html](http://redwood-data.org/indoor_lidar_rgbd/download.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "        \n",
    "# Helper function to draw registrations (reccomended)\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating point clouds from image data\n",
    "Now we are going to try to create our own point clouds from RGB+depth images.\n",
    "First, we load two RGBD images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images. We have images 000000 - 0000400\n",
    "color_raw0 = o3d.io.read_image(\"RGBD/color/000000.jpg\")\n",
    "depth_raw0 = o3d.io.read_image(\"RGBD/depth/000000.png\")\n",
    "\n",
    "color_raw1 = o3d.io.read_image(\"RGBD/color/000005.jpg\")\n",
    "depth_raw1 = o3d.io.read_image(\"RGBD/depth/000005.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create point clouds from rgb + depth images.\n",
    "\n",
    "If you set `convert_rgb_to_intensity = False` you will retain the colors from the rgb image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw1, \n",
    "    depth_raw1, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "#show images\n",
    "fig= plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.title('Redwood grayscale0 image')\n",
    "plt.imshow(rgbd_image0.color)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Redwood depth0 image')\n",
    "plt.imshow(rgbd_image0.depth)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Redwood grayscale1 image')\n",
    "plt.imshow(rgbd_image1.color)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('Redwood depth1 image')\n",
    "plt.imshow(rgbd_image1.depth)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images to point cloud\n",
    "Now we create point clouds from the RGBD images we just loaded/created.\n",
    "\n",
    "\n",
    "Here, we use `PinholeCameraIntrinsicParameters.PrimeSenseDefault` as default camera parameters. \n",
    "\n",
    "It has an image resolution of 640x480, focal length of ($f_x$, $f_y$) = (525.0, 525.0), and optical center ($c_x$, $c_y$) = (319.5, 239.5). \n",
    "\n",
    "An identity matrix is used as default extrinsic parameters. `pcd.transform` applies an up-down flip transformation on the point cloud for an improved visualization.\n",
    "\n",
    "\n",
    "If execution becomes too slow you can downsample the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source pointcloud\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image0, camera)\n",
    "\n",
    "# Target pointcloud\n",
    "target = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image1, camera)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "source.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "# Draw\n",
    "draw_registrations(source, target, recolor=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of pointclouds\n",
    "\n",
    "Before we can run ICP, we evaluate our source and target point clouds. This gives us a feeling if we need a better initial transformation or not.\n",
    "From (http://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html):\n",
    "\n",
    "\"The function `evaluate_registration` calculates two main metrics. \n",
    "- `fitness` measures the overlapping area (# of inlier correspondences / # of points in target). The higher the better. \n",
    "- `inlier_rmse` measures the RMSE of all inlier correspondences. The lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "#Evaluate registration\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP\n",
    "\n",
    "Now try to call icp with your point clouds and your initial transformation.\n",
    "\n",
    "Initially we use:\n",
    "```Python\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# ICP code here\n",
    "###\n",
    "\n",
    "#icp_result = o3d.pipelines.registration.registration_icp()\n",
    "\n",
    "draw_registrations(source, target, icp_result.transformation, True)\n",
    "draw_registrations(source, target, icp_result.transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exersices\n",
    "\n",
    "### A)\n",
    "If you increase the amount of steps from the original image so from i.e. 000000.jpg<>000005.jpg to 00000.jpg<>000300.jpg, what happens?\n",
    "### B)\n",
    "Can you tweak the parameters `threshold` and `trans_init` to combat some of the ill effects that starts appearing?\n",
    "### C)\n",
    "Again try to use \n",
    "```Python\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "```\n",
    "\n",
    "This requires you to find the normals for each point cloud use:\n",
    "```python\n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "```\n",
    "Compare the resulting translations of the two methods. Is one better than the other?\n",
    "### D)\n",
    "Extend this and try to see how much of the bedroom you can reconstruct from the RGB and depth images.\n",
    "You can extend a point cloud by `new = source + target`. Remember to resample the point cloud after a view additions so it does not get too large: `down_source = source.voxel_down_sample(voxel_size=0.05)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
