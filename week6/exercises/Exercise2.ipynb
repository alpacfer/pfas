{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Point Cloud Clustering\n",
    "\n",
    "In this exercise, we focus on clustering point clouds using K-means and DBSCAN to segment different regions. A key aspect of this exercise is to understand how adding more information to each point—like surface normals—can improve the clustering results. We will use a cube as a simple geometric shape to explore these concepts and gradually move on to more complex shapes and real-world point clouds.\n",
    "\n",
    "## Overview of the Exercise\n",
    "\n",
    "### The Cube and Clustering\n",
    "\n",
    "- **Point Cloud of a Cube**: We create a point cloud of a cube using `Open3D`. A point cloud is a set of data points in 3D space that represents the surface of a geometric object. In this case, the cube serves as an initial, simple shape to test our clustering methods.\n",
    "- **Clustering the Cube**: Clustering aims to group points that belong to the same region or surface. For the cube, the ideal clustering would be to separate points based on the six faces of the cube.\n",
    "- **Challenge**: Basic K-means clustering, which relies only on point positions (XYZ coordinates), often struggles to accurately separate the cube's faces. This is because points on different sides of the cube may be close together in 3D space, making it difficult for K-means to differentiate them using position alone.\n",
    "- **Solution Strategy**: To address this, we explore adding surface normals—vectors that indicate the direction each point faces—to the clustering process. Normals provide extra information about the orientation of each point, helping to distinguish points on different surfaces even when their positions are similar.\n",
    "\n",
    "### What We Aim to Achieve\n",
    "\n",
    "- **Segmentation of Cube Faces**: By using K-means with additional features like normals, we aim to improve the segmentation of the cube into its six distinct faces.\n",
    "- **Experimenting with Feature Weighting**: We also test how scaling the influence of positional versus directional information (normals) affects clustering results.\n",
    "- **Clustering Different Geometric Shapes**: Beyond the cube, we combine various geometric shapes into a single point cloud to test the algorithm’s ability to distinguish between different structures.\n",
    "- **Applying Clustering to Real Data**: We apply our methods to a more complex point cloud dataset, `fragment.ply`, to understand how these techniques generalize to real-world data.\n",
    "- **Using DBSCAN for Variable Density Clustering**: Finally, we explore DBSCAN, which is useful for identifying clusters of varying shapes and densities, making it a powerful alternative to K-means for more irregular datasets.\n",
    "\n",
    "## Overview of Tasks\n",
    "\n",
    "### Task A: K-means with Normals\n",
    "\n",
    "**Objective**: Improve clustering by combining point cloud coordinates (XYZ) with normals.\n",
    "\n",
    "1. **Estimate Normals for the Point Cloud**:\n",
    "   - We estimate normals for each point in the point cloud using Open3D.\n",
    "   - Normals are vectors perpendicular to the surface of each point, providing information about the direction each point faces.\n",
    "   - **Purpose**: Normals help describe the orientation of points, which can improve clustering by differentiating points based on their direction.\n",
    "\n",
    "2. **Combine Coordinates and Normals**:\n",
    "   - We combine the XYZ coordinates of each point with their corresponding normals to create a new feature set.\n",
    "   - This results in a 6-dimensional feature vector for each point, containing both positional and directional information.\n",
    "   - **Purpose**: Including both position and orientation information allows the clustering algorithm to better distinguish between different regions.\n",
    "\n",
    "3. **Apply K-means Clustering**:\n",
    "   - K-means is applied to the combined features with `n_clusters=6`, aiming to segment the cube into six clusters.\n",
    "   - We use `init='random'` to randomly initialize the centroids.\n",
    "   - **Purpose**: The goal is to achieve more accurate segmentation by leveraging the extra information provided by the normals.\n",
    "\n",
    "4. **Visualize the Results**:\n",
    "   - We visualize the segmented point cloud, with each cluster displayed in a distinct color.\n",
    "   - **Observation**: By using both XYZ and normals, K-means can better segment points on each face of the cube.\n",
    "\n",
    "---\n",
    "\n",
    "### Task B: Weighted Feature Clustering\n",
    "\n",
    "**Objective**: Experiment with the influence of spatial and directional features by weighting the normals.\n",
    "\n",
    "1. **Estimate Normals for the Point Cloud**:\n",
    "   - Similar to Task A, we first estimate normals for the point cloud.\n",
    "\n",
    "2. **Combine XYZ Coordinates with Weighted Normals**:\n",
    "   - We multiply the normals by a weighting factor to increase or decrease their influence in the clustering process.\n",
    "   - For example, using a weight factor of 10 gives more importance to the direction of the normals.\n",
    "   - **Purpose**: Adjusting the weight of normals allows us to control how much the orientation of points affects the clustering result.\n",
    "\n",
    "3. **Apply K-means Clustering**:\n",
    "   - K-means is applied to the weighted feature set with `n_clusters=6`.\n",
    "   - **Purpose**: This allows us to see if giving more importance to the normals can improve the segmentation of the cube’s faces.\n",
    "\n",
    "4. **Visualize the Results**:\n",
    "   - Visualize the point cloud to see if the weighting improved the clustering.\n",
    "   - **Observation**: Adjusting the weight can help separate the faces more clearly, but the results depend on finding the right balance between position and orientation.\n",
    "\n",
    "---\n",
    "\n",
    "### Task C: Clustering Multiple Shapes\n",
    "\n",
    "**Objective**: Test the clustering algorithm’s ability to distinguish between different geometric shapes.\n",
    "\n",
    "1. **Create and Combine Different Shapes**:\n",
    "   - We create several geometric shapes using Open3D, such as a tetrahedron, octahedron, icosahedron, and torus.\n",
    "   - These shapes are combined into a single point cloud.\n",
    "   - **Purpose**: Combining different shapes tests how well the clustering algorithm can distinguish between different geometries.\n",
    "\n",
    "2. **Sample Points from the Combined Mesh**:\n",
    "   - We sample points uniformly from the combined mesh to create a point cloud.\n",
    "   - **Purpose**: Sampling provides a dense representation of the combined shapes, which is necessary for accurate clustering.\n",
    "\n",
    "3. **Estimate Normals for the Point Cloud**:\n",
    "   - Normals are estimated for each point to provide information about surface orientation.\n",
    "\n",
    "4. **Combine XYZ Coordinates and Normals**:\n",
    "   - We concatenate the XYZ coordinates and normals to create a 6-dimensional feature set.\n",
    "   - **Purpose**: Including both position and orientation helps distinguish different shapes that overlap in space.\n",
    "\n",
    "5. **Apply K-means Clustering**:\n",
    "   - We set `n_clusters=4`, corresponding to the four distinct shapes.\n",
    "   - **Purpose**: The goal is to see if K-means can correctly identify each geometric shape as a separate cluster.\n",
    "\n",
    "6. **Visualize the Results**:\n",
    "   - Visualize the clustered point cloud with distinct colors for each cluster.\n",
    "   - **Observation**: Successful clustering indicates that K-means can distinguish between shapes when given enough spatial and directional information.\n",
    "\n",
    "---\n",
    "\n",
    "### Task D: Segmenting a New Point Cloud\n",
    "\n",
    "**Objective**: Apply clustering to a new point cloud dataset and test the clustering approach on more complex data.\n",
    "\n",
    "1. **Load the Point Cloud**:\n",
    "   - We load a new point cloud from `pointclouds/fragment.ply` using Open3D.\n",
    "   - **Purpose**: Using a new dataset tests the generalization of our clustering method.\n",
    "\n",
    "2. **Downsample the Point Cloud**:\n",
    "   - We use a voxel grid to downsample the point cloud, reducing the number of points.\n",
    "   - **Purpose**: Downsampling helps reduce computational complexity, making it easier to work with large datasets.\n",
    "\n",
    "3. **Estimate Normals**:\n",
    "   - Normals are estimated for each point in the downsampled point cloud.\n",
    "\n",
    "4. **Compute FPFH Features**:\n",
    "   - We compute Fast Point Feature Histograms (FPFH) to describe the local geometry around each point.\n",
    "   - **Purpose**: FPFH features capture more descriptive information about local surface variations, which can help improve clustering accuracy.\n",
    "\n",
    "5. **Combine XYZ Coordinates and Normals**:\n",
    "   - Combine XYZ coordinates with normals to create a feature set for clustering.\n",
    "\n",
    "6. **Apply DBSCAN Clustering**:\n",
    "   - We use DBSCAN to cluster the points based on their density, with parameters `eps` (neighborhood radius) and `min_samples`.\n",
    "   - **Purpose**: DBSCAN is useful for detecting clusters with varying densities and separating noise.\n",
    "\n",
    "7. **Visualize the Results**:\n",
    "   - Visualize the clustered point cloud with different colors for each cluster.\n",
    "   - **Observation**: DBSCAN can effectively identify dense regions and separate noise, providing meaningful segmentation of the point cloud.\n",
    "\n",
    "---\n",
    "\n",
    "### Task E: Using DBSCAN\n",
    "\n",
    "**Objective**: Explore the DBSCAN algorithm with different parameter settings and analyze its clustering performance.\n",
    "\n",
    "1. **Set DBSCAN Parameters**:\n",
    "   - Set `eps` (neighborhood size) and `min_points` (minimum points required to form a cluster).\n",
    "   - **Purpose**: Adjusting these parameters controls how DBSCAN groups points, affecting the number and size of clusters.\n",
    "\n",
    "2. **Apply DBSCAN to the Point Cloud**:\n",
    "   - Apply DBSCAN to the point cloud using Open3D’s `cluster_dbscan()` method.\n",
    "   - **Purpose**: DBSCAN is ideal for clustering data with varying densities and identifying outliers.\n",
    "\n",
    "3. **Visualize the Results**:\n",
    "   - Visualize the segmented point cloud to analyze the clusters.\n",
    "   - **Observation**: By tweaking `eps` and `min_points`, we can refine the clustering to capture different details in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts and Terminology\n",
    "\n",
    "- **Point Cloud**: A collection of 3D points representing the surface of an object.\n",
    "- **Normals**: Vectors perpendicular to the surface at each point, indicating the direction the point faces.\n",
    "- **K-means Clustering**: Groups data into a predefined number of clusters based on their features.\n",
    "- **DBSCAN**: Finds clusters based on point density, useful for real-world data with noise.\n",
    "- **FPFH**: Describes the local geometry around points, aiding in clustering.\n",
    "\n",
    "## Libraries Used\n",
    "\n",
    "- **Open3D**: For point cloud operations and visualization.\n",
    "- **NumPy**: For numerical operations.\n",
    "- **Scikit-Learn**: For implementing clustering algorithms.\n",
    "- **Matplotlib**: For visualizing clusters.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand how to improve clustering by using additional features.\n",
    "- Experiment with clustering parameters to achieve better segmentation.\n",
    "- Apply clustering to both simple and complex point clouds.\n",
    "- Visualize the results to understand how each method affects segmentation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Today we are going to continue to work on point clouds.\n",
    "We will work on clustering point clouds. That enables us to segment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels_on_model(pcl,labels):\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "    pcl_temp = copy.deepcopy(pcl)\n",
    "    max_label = labels.max()\n",
    "    print(\"%s has %d clusters\" % (pcl_name, max_label + 1))\n",
    "    colors = cmap(labels / (max_label if max_label > 0 else 1))\n",
    "    colors[labels < 0] = 0\n",
    "    pcl_temp.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    o3d.visualization.draw_geometries([pcl_temp])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means on a cube\n",
    "We created a point cloud using `open3d`.\n",
    "Our goal is to segment each side using k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube has 10000 points\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "pcl_name = 'Cube'\n",
    "density = 1e4 # density of sample points to create\n",
    "pcl = o3d.geometry.TriangleMesh.create_box().sample_points_uniformly(int(density))\n",
    "eps = 0.4\n",
    "print(\"%s has %d points\" % (pcl_name, np.asarray(pcl.points).shape[0]))\n",
    "o3d.visualization.draw_geometries([pcl])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just use k-means out of the box with the point cloud, we will get what just has been visualized.\n",
    "\n",
    "Note: Using the '+' and '-' keys in the viewer will increase/decrease the size of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube has 6 clusters\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=6, init='random',\n",
    "            n_init=10, max_iter=300, tol=1e-04, random_state=0)\n",
    "\n",
    "# Get the points from the pointcloud as nparray\n",
    "xyz = np.asarray(pcl.points)\n",
    "labels = km.fit_predict(xyz)\n",
    "draw_labels_on_model(pcl, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get six clusters, but they do not span a side.\n",
    "\n",
    "We try again, but this time we instead use the normals of the cube as input for k-means.\n",
    "\n",
    "The normals for each plane should be parallel with the other normals from said plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube has 6 clusters\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute normals for the point cloud\n",
    "pcl.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Extract XYZ and normal vectors from the point cloud\n",
    "xyz = np.asarray(pcl.points)  # Shape (N, 3)\n",
    "normals = np.asarray(pcl.normals)  # Shape (N, 3)\n",
    "\n",
    "# Step 2: Concatenate XYZ coordinates and normals to form the input feature matrix\n",
    "features = np.hstack((xyz, normals))  # Shape (N, 6)\n",
    "\n",
    "# Step 3: Apply K-means clustering\n",
    "km = KMeans(n_clusters=6, init='random', n_init=10, max_iter=300, tol=1e-4, random_state=0)\n",
    "labels = km.fit_predict(features)\n",
    "\n",
    "# Step 4: Visualize the clustered point cloud\n",
    "draw_labels_on_model(pcl, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still does not work, opposite sides will also have normals that point the other way ($\\vec{n}$ and $-\\vec{n}$).\n",
    "\n",
    "So, to combat this we can attempt to use the xyz coordinates and the normals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More exercises\n",
    "\n",
    "### A) K-means continued.\n",
    "\n",
    "Combine the point cloud points (xyz) with the normals and do k-means.\n",
    "\n",
    "```xyz_n = np.concatenate((xyz, normals), axis=1)```\n",
    "\n",
    "Do you get better clusters?\n",
    "Why would adding the normals help?\n",
    "\n",
    "### B) \n",
    "Try weighting either the points or normals by scaling them by some factor. Can this perfectly segment each of the faces of the cube?\n",
    "### C)\n",
    "Try to cluster all the different shapes using k means.\n",
    "```{Python}\n",
    "d = 4\n",
    "mesh = o3d.geometry.TriangleMesh.create_tetrahedron().translate((-d, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_octahedron().translate((0, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_icosahedron().translate((d, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_torus().translate((-d, -d, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_moebius(twists=1).translate(\n",
    "    (0, -d, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_moebius(twists=2).translate(\n",
    "    (d, -d, 0))\n",
    "mesh.sample_points_uniformly(int(1e5)), 0.5\n",
    "```\n",
    "\n",
    "### D)\n",
    "Now try segmenting a different point cloud located at `pointclouds/fragment.ply`\n",
    "Are you able to cluster the point cloud?\n",
    "\n",
    "Which features could be useful to segment this point cloud?\n",
    "- fpfh features?\n",
    "- xyz\n",
    "- normals \n",
    "- colors\n",
    "\n",
    "Are you able to get clusters that make sense? Why?\n",
    "\n",
    "### E)\n",
    "Use the built-in `cluster_dbscan` algorithm.\n",
    "Tweak the parameters and see what you get out.\n",
    "\n",
    "Attempt on the combined figures and on `fragment.ply`\n",
    "```{Python}\n",
    "#eps (float) – Density parameter that is used to find neighbouring points.\n",
    "eps = 0.02\n",
    "\n",
    "#min_points (int) – Minimum number of points to form a cluster.\n",
    "min_points = 10\n",
    "\n",
    "labels = np.array(pcl.cluster_dbscan(eps=eps, min_points=min_points, print_progress=True))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube has 6 clusters\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Estimate normals for the point cloud\n",
    "pcl.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Step 2: Combine xyz coordinates with normals\n",
    "xyz = np.asarray(pcl.points)\n",
    "normals = np.asarray(pcl.normals)\n",
    "xyz_n = np.concatenate((xyz, normals), axis=1)\n",
    "\n",
    "# Step 3: Apply K-means clustering to the combined features\n",
    "km = KMeans(n_clusters=6, init='random', n_init=10, max_iter=300, tol=1e-4, random_state=0)\n",
    "labels = km.fit_predict(xyz_n)\n",
    "\n",
    "# Step 4: Visualize the clustered point cloud\n",
    "draw_labels_on_model(pcl, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube has 6 clusters\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Estimate normals for the point cloud\n",
    "pcl.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Step 2: Combine XYZ coordinates with weighted normals\n",
    "xyz = np.asarray(pcl.points)\n",
    "normals = np.asarray(pcl.normals)\n",
    "\n",
    "# Weighting normals by a factor to adjust influence\n",
    "weight_factor = 10  # Adjust this value to experiment with different influences\n",
    "weighted_normals = normals * weight_factor\n",
    "\n",
    "# Concatenate the weighted normals with the xyz coordinates\n",
    "xyz_weighted = np.concatenate((xyz, weighted_normals), axis=1)\n",
    "\n",
    "# Step 3: Apply K-means clustering to the combined weighted features\n",
    "km = KMeans(n_clusters=6, init='random', n_init=10, max_iter=300, tol=1e-4, random_state=0)\n",
    "labels = km.fit_predict(xyz_weighted)\n",
    "\n",
    "# Step 4: Visualize the clustered point cloud\n",
    "draw_labels_on_model(pcl, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import copy\n",
    "\n",
    "# Step 1: Create and combine different shapes (without Möbius)\n",
    "d = 4\n",
    "mesh = o3d.geometry.TriangleMesh.create_tetrahedron().translate((-d, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_octahedron().translate((0, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_icosahedron().translate((d, 0, 0))\n",
    "mesh += o3d.geometry.TriangleMesh.create_torus().translate((-d, -d, 0))\n",
    "\n",
    "# Step 2: Sample points from the combined mesh to create a point cloud\n",
    "pcl = mesh.sample_points_uniformly(int(1e5))  # Sampling approximately 100k points\n",
    "\n",
    "# Step 3: Estimate normals for the point cloud\n",
    "pcl.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Step 4: Combine XYZ coordinates and normals\n",
    "xyz = np.asarray(pcl.points)\n",
    "normals = np.asarray(pcl.normals)\n",
    "\n",
    "# Combine XYZ coordinates and normals\n",
    "xyz_n = np.concatenate((xyz, normals), axis=1)\n",
    "\n",
    "# Step 5: Apply K-means clustering\n",
    "n_clusters = 4  # Four distinct shapes to segment (since we have removed Möbius)\n",
    "km = KMeans(n_clusters=n_clusters, init='random', n_init=10, max_iter=300, tol=1e-4, random_state=0)\n",
    "labels = km.fit_predict(xyz_n)\n",
    "\n",
    "# Step 6: Visualize the clustered point cloud\n",
    "def draw_labels_on_model(pcl, labels):\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "    pcl_temp = copy.deepcopy(pcl)\n",
    "    max_label = labels.max()\n",
    "    colors = cmap(labels / (max_label if max_label > 0 else 1))\n",
    "    colors[labels < 0] = 0\n",
    "    pcl_temp.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    o3d.visualization.draw_geometries([pcl_temp])\n",
    "\n",
    "draw_labels_on_model(pcl, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud...\n",
      "Point cloud loaded with 196133 points.\n",
      "Downsampled point cloud with 94743 points.\n",
      "Estimating normals...\n",
      "Normals estimation completed.\n",
      "Computing FPFH features...\n",
      "FPFH features computed with shape: (94743, 33)\n",
      "Extracting XYZ coordinates and normals...\n",
      "XYZ coordinates shape: (94743, 3), Normals shape: (94743, 3)\n",
      "Combining features (XYZ, normals)...\n",
      "Reduced feature set shape: (94743, 6)\n",
      "Applying DBSCAN clustering...\n",
      "DBSCAN clustering completed.\n",
      "Number of clusters found: 167\n",
      "Number of noise points: 3559\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import DBSCAN\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define a function to generate distinct colors\n",
    "def generate_distinct_colors(n):\n",
    "    np.random.seed(42)  # Seed for reproducibility\n",
    "    return np.random.rand(n, 3)\n",
    "\n",
    "# Step 1: Load the point cloud\n",
    "print(\"Loading point cloud...\")\n",
    "pcl = o3d.io.read_point_cloud(\"TestData/fragment.ply\")\n",
    "print(f\"Point cloud loaded with {len(pcl.points)} points.\")\n",
    "\n",
    "# Step 1.1: Downsample the point cloud to reduce computational load\n",
    "voxel_size = 0.01  # Adjust voxel size to control downsampling density\n",
    "pcl = pcl.voxel_down_sample(voxel_size=voxel_size)\n",
    "print(f\"Downsampled point cloud with {len(pcl.points)} points.\")\n",
    "\n",
    "# Step 2: Estimate normals\n",
    "print(\"Estimating normals...\")\n",
    "pcl.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "print(\"Normals estimation completed.\")\n",
    "\n",
    "# Step 3: Compute FPFH features\n",
    "print(\"Computing FPFH features...\")\n",
    "radius_feature = 0.25\n",
    "fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    pcl, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100)\n",
    ").data.T\n",
    "print(f\"FPFH features computed with shape: {fpfh.shape}\")\n",
    "\n",
    "# Step 4: Extract XYZ and normal features\n",
    "print(\"Extracting XYZ coordinates and normals...\")\n",
    "xyz = np.asarray(pcl.points)\n",
    "normals = np.asarray(pcl.normals)\n",
    "print(f\"XYZ coordinates shape: {xyz.shape}, Normals shape: {normals.shape}\")\n",
    "\n",
    "# Step 5: Combine a reduced set of features (XYZ, normals only)\n",
    "print(\"Combining features (XYZ, normals)...\")\n",
    "features = np.concatenate((xyz, normals), axis=1)\n",
    "print(f\"Reduced feature set shape: {features.shape}\")\n",
    "\n",
    "# Step 6: Apply DBSCAN clustering\n",
    "print(\"Applying DBSCAN clustering...\")\n",
    "eps_value = 0.1  # Reduce eps to limit neighborhood size\n",
    "min_samples = 5  # Reduce min_samples to improve runtime\n",
    "db = DBSCAN(eps=eps_value, min_samples=min_samples).fit(features)\n",
    "print(\"DBSCAN clustering completed.\")\n",
    "\n",
    "# Step 7: Extract labels\n",
    "labels = db.labels_\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = list(labels).count(-1)\n",
    "print(f\"Number of clusters found: {n_clusters}\")\n",
    "print(f\"Number of noise points: {n_noise}\")\n",
    "\n",
    "# Step 8: Visualize the segmented point cloud with distinct colors\n",
    "def draw_labels_on_model(pcl, labels):\n",
    "    max_label = labels.max()\n",
    "    n_clusters = max_label + 1\n",
    "\n",
    "    # Generate distinct colors for each cluster, plus an extra one for noise points\n",
    "    distinct_colors = generate_distinct_colors(n_clusters + 1)\n",
    "    cmap = ListedColormap(distinct_colors)\n",
    "\n",
    "    pcl_temp = copy.deepcopy(pcl)\n",
    "    colors = cmap(labels / max_label if max_label > 0 else 1)\n",
    "    colors[labels < 0] = [0.1, 0.1, 0.1, 1.0]  # Assign dark gray with full alpha to noise points\n",
    "    pcl_temp.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    # Visualize the point cloud with distinct cluster colors\n",
    "    o3d.visualization.draw_geometries([pcl_temp])\n",
    "\n",
    "# Use the draw_labels_on_model function after completing clustering\n",
    "draw_labels_on_model(pcl, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cd5a613775d973e3ebb98e1e77334e79b1df328fc590baa0c4f920a9a4d0a201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
